# IT Operations Dashboard - Complete Documentation

## Table of Contents
1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Features](#features)
4. [Technical Stack](#technical-stack)
5. [Installation](#installation)
6. [Configuration](#configuration)
7. [Usage Guide](#usage-guide)
8. [Component Structure](#component-structure)
9. [Data Models](#data-models)
10. [API Integration](#api-integration)
11. [Authentication](#authentication)
12. [Backup and Restore](#backup-and-restore)
13. [Deployment](#deployment)
14. [Performance Considerations](#performance-considerations)
15. [Security Considerations](#security-considerations)
16. [Future Enhancements](#future-enhancements)
17. [Troubleshooting](#troubleshooting)
18. [FAQ](#faq)

## Project Overview

The IT Operations Dashboard is a comprehensive web application designed to visualize and analyze IT service management data, specifically focused on incidents and service requests. The application provides real-time insights into IT operations, helping teams monitor performance, identify trends, and make data-driven decisions.

The dashboard is built as a client-side React application that processes Excel files containing incident and request data. It offers various visualization and analysis tools, including AI-powered insights through OpenAI integration.

### Key Objectives

- Provide a comprehensive view of IT incidents and service requests
- Enable detailed analysis by priority, category, location, and time
- Identify trends and patterns in IT operations
- Offer AI-powered insights and recommendations
- Support decision-making with data-driven visualizations

## Architecture

The IT Operations Dashboard follows a modern React single-page application (SPA) architecture with the following key characteristics:

### Client-Side Architecture

- **Component-Based Structure**: Modular components for reusability and maintainability
- **State Management**: React's built-in state management with hooks
- **Data Processing**: Client-side data processing and visualization
- **Responsive Design**: Mobile-first approach using Tailwind CSS
- **File-Based Data**: Excel file import for data analysis (no backend database)
- **AI Analysis**: Integration with OpenAI for advanced data insights

### Data Flow

1. User uploads Excel files containing incident or request data
2. Application processes and validates the data client-side
3. Data is stored in React state and used for visualization and analysis
4. User interacts with various dashboard components to analyze the data
5. For AI analysis, anonymized data is sent to OpenAI API and results are displayed

## Features

### Incident Management
- Incident tracking and visualization
- Priority-based analysis
- SLA compliance monitoring
- Category and subcategory analysis
- Assignment group performance metrics
- Historical trend analysis

### Request Management
- Request tracking and visualization
- Priority and category analysis
- SLA compliance monitoring
- Completion rate analysis
- User and location-based insights

### Advanced Analytics
- AI-powered predictive analysis
- Shift-based performance metrics
- Root cause identification
- Recommendation engine
- Impact analysis

### User Interface
- Dark mode interface
- Interactive charts and graphs
- Responsive design for all devices
- Filterable data views
- Detailed drill-down capabilities

## Technical Stack

### Frontend
- **React**: UI library (v18.2.0)
- **TypeScript**: Type-safe JavaScript
- **Vite**: Build tool and development server
- **Tailwind CSS**: Utility-first CSS framework
- **Recharts**: Chart visualization library
- **Lucide React**: Icon library
- **date-fns**: Date manipulation library
- **XLSX**: Excel file parsing

### Data Processing
- **Fuse.js**: Fuzzy search functionality
- **OpenAI API**: AI-powered analysis

### Development Tools
- **ESLint**: Code linting
- **TypeScript-ESLint**: TypeScript-specific linting
- **Autoprefixer**: CSS vendor prefixing
- **PostCSS**: CSS processing

## Installation

### Prerequisites
- Node.js (v18.0.0 or higher)
- npm (v8.0.0 or higher)

### Setup Steps

1. Clone the repository:
```bash
git clone <repository-url>
cd it-operations-dashboard
```

2. Install dependencies:
```bash
npm install
```

3. Create environment files:

Create `.env.development`:
```
VITE_APP_ENV=development
VITE_APP_TITLE="IT Operations Dashboard (Development)"
VITE_OPENAI_API_KEY=your_openai_api_key
```

Create `.env.production`:
```
VITE_APP_ENV=production
VITE_APP_TITLE="IT Operations Dashboard"
VITE_OPENAI_API_KEY=your_openai_api_key
```

4. Start the development server:
```bash
npm run dev
```

5. Access the application:
Open your browser and navigate to `http://localhost:4000`

## Configuration

### Environment Variables

The application uses the following environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `VITE_APP_ENV` | Environment name | `development` |
| `VITE_APP_TITLE` | Application title | `IT Operations Dashboard` |
| `VITE_OPENAI_API_KEY` | OpenAI API key | - |

### Environment Files

- `.env.development`: Development environment variables
- `.env.production`: Production environment variables

### OpenAI API Configuration

The application uses OpenAI's API for AI-powered analysis. You need to provide a valid API key in the environment variables.

```typescript
// OpenAI API initialization
const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true
});
```

## Usage Guide

### Authentication

1. Access the application URL
2. Enter the following credentials:
   - Username: `Onset-ISRA`
   - Password: `Socorro01@`
3. Click "Login" to access the dashboard

### Data Import

1. After logging in, you'll see the file upload screen
2. Click "Load Incidents" or "Load Requests" depending on your data type
3. Select an Excel file (.xlsx or .xls) containing your data
4. The system will process your file and display the dashboard

### Dashboard Navigation

- Use the analysis cards to navigate between different views
- Click on charts and data points to drill down into more detailed information
- Use the search bar to find specific incidents or requests
- Use the date filters to focus on specific time periods

### Incident Analysis

- **Priority Analysis**: View incidents by priority level
- **Category Analysis**: View incidents by category and subcategory
- **Group Analysis**: View incidents by assignment group
- **SLA Analysis**: View SLA compliance metrics
- **User Analysis**: View incidents by caller
- **Location Analysis**: View incidents by location
- **Shift Analysis**: View incidents by work shift

### Request Analysis

- **Request Analysis**: Overview of all requests
- **Category Analysis**: View requests by category
- **Priority Analysis**: View requests by priority
- **History Analysis**: View historical request data
- **SLA Analysis**: View SLA compliance for requests

### AI-Powered Insights

- **AI Analyst**: Get AI-powered insights for incidents
- **AI Predictive Analysis**: Get AI-powered insights for requests

## Component Structure

The application is organized into the following component structure:

### Main Components

- **App.tsx**: Main application component
- **RequestDashboard.tsx**: Dashboard for request analysis
- **ExecutiveDashboard.tsx**: Executive summary dashboard

### Authentication Components

- **LoginScreen.tsx**: Login screen component
- **AuthContext.tsx**: Authentication context provider

### Dashboard Components

- **DashboardHeader.tsx**: Header component for dashboards
- **SearchBar.tsx**: Search and filter component
- **StatsCard.tsx**: Card component for displaying statistics
- **CategoryCard.tsx**: Card component for category selection

### Dashboard Block Structure

#### Indicadores Operacionais
O bloco de Indicadores Operacionais é composto por 6 cards/botões principais, cada um com sua funcionalidade específica:

1. **Chamados Pendentes**
   - Descrição: Status atual dos chamados
   - Ícone: AlertCircle
   - Função: Abre o modal de chamados pendentes
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[0]

2. **SLA**
   - Descrição: Acordo de nível de serviço
   - Ícone: Clock
   - Função: Ativa a análise de SLA
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[1]

3. **Por Categoria**
   - Descrição: Distribuição por tipo
   - Ícone: BarChart3
   - Função: Ativa a análise por categoria
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[2]

4. **Por Grupo**
   - Descrição: Distribuição por equipe
   - Ícone: Users
   - Função: Ativa a análise por grupo
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[3]

5. **Por Usuários**
   - Descrição: Distribuição por usuários
   - Ícone: UserCircle
   - Função: Ativa a análise por usuários
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[4]

6. **Top Chamados – Drilldown por String Associado**
   - Descrição: Drilldown por Categoria, Subcategoria e String Associado
   - Ícone: BarChart2
   - Função: Ativa a análise detalhada por string associado
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[5]

7. **Análise de Indicadores Associados**
   - Descrição: Análise integrada de Função, Grupo e String Associado com turnos
   - Ícone: Users2
   - Função: Ativa a análise detalhada de indicadores associados
   - Componente: `DashboardSections.tsx`
   - Localização: Seção 'operacional' > items[6]
   - Funcionalidades:
     - Visualização por turno (manhã, tarde, noite)
     - Distribuição por função associada
     - Análise por grupo de atribuição
     - Métricas por string associado
     - Gráficos interativos de desempenho
     - Filtros por período e turno

##### Estrutura do Componente
```typescript
const sections = {
  operacional: {
    title: "Indicadores Operacionais",
    description: "Métricas de operação diária",
    icon: BarChart3,
    color: "bg-blue-600",
    hoverColor: "hover:bg-blue-700",
    items: [
      // Array de items conforme listado acima
    ]
  }
}
```

##### Estilização
- Grid responsivo: `grid-cols-1 md:grid-cols-2 lg:grid-cols-4`
- Cores: 
  - Fundo padrão: `bg-[#1E293B]`
  - Hover: `hover:bg-[#2D3748]`
  - Ativo: `bg-indigo-600`
- Transições: `transition-colors`

##### Manutenção
Para adicionar ou modificar cards:
1. Edite o array `items` dentro do objeto `sections.operacional`
2. Mantenha a estrutura de cada item com: title, description, icon, sectionKey e onClick
3. Atualize a documentação se necessário

### Analysis Components

- **CategoryAnalysis.tsx**: Analysis by category
- **SoftwareAnalysis.tsx**: Analysis of software-related incidents
- **HardwareAnalysis.tsx**: Analysis of hardware-related incidents
- **GroupAnalysis.tsx**: Analysis by assignment group
- **SLAAnalysis.tsx**: Analysis of SLA compliance
- **UserAnalysis.tsx**: Analysis by user
- **LocationAnalysis.tsx**: Analysis by location
- **AnalystAnalysis.tsx**: Analysis by analyst
- **ShiftHistoryAnalysis.tsx**: Analysis by shift

### AI Components

- **AIAnalyst.tsx**: AI-powered incident analysis
- **AIPredictiveAnalysis.tsx**: AI-powered request analysis

### Modal Components

- **IncidentDetails.tsx**: Modal for incident details
- **CriticalIncidentsModal.tsx**: Modal for critical incidents
- **PendingIncidentsModal.tsx**: Modal for pending incidents
- **OnHoldIncidentsModal.tsx**: Modal for on-hold incidents

### Utility Components

- **FileUpload.tsx**: Component for file upload
- **FileUploadSelector.tsx**: Component for selecting file type
- **CalendarSelector.tsx**: Component for date selection

## Data Models

### Incident Model

```typescript
export interface Incident {
  Number: string;
  Opened: string;
  ShortDescription: string;
  Caller: string;
  Priority: string;
  State: string;
  Category: string;
  Subcategory: string;
  AssignmentGroup: string;
  AssignedTo: string;
  Updated: string;
  UpdatedBy: string;
  BusinessImpact: string;
  ResponseTime: string;
  Location?: string;
  CommentsAndWorkNotes?: string;
}
```

### Request Model

```typescript
export interface Request {
  Number: string;
  Opened: string;
  ShortDescription: string;
  RequestItem: string;
  RequestedForName: string;
  Priority: string;
  State: string;
  AssignmentGroup: string;
  AssignedTo: string;
  Updated: string;
  UpdatedBy: string;
  CommentsAndWorkNotes: string;
  BusinessImpact: string;
  [key: string]: string; // For dynamic field access
}
```

### Analyst Model

```typescript
export interface Analyst {
  name: string;
  level: string;
  startTime: string;
  endTime: string;
  schedule: string;
  location?: string;
}
```

### Historical Data Model

```typescript
export interface HistoricalData {
  month: string; // Format: YYYY-MM
  incidents: {
    total: number;
    byPriority: Record<string, number>;
    byCategory: Record<string, number>;
    byState: Record<string, number>;
    slaCompliance: {
      withinSLA: number;
      outsideSLA: number;
      percentage: number;
    };
  };
  requests: {
    total: number;
    byPriority: Record<string, number>;
    byStatus: Record<string, number>;
    byCategory: Record<string, number>;
    completionRate: number;
  };
}
```

## API Integration

### OpenAI API

The application integrates with OpenAI's API to provide AI-powered analysis of incident and request data.

#### Incident Analysis API Call

```typescript
const completion = await openai.chat.completions.create({
  model: "gpt-4-turbo-preview",
  messages: [
    { role: "system", content: systemPrompt },
    {
      role: "user",
      content: JSON.stringify({
        task: "Analyze these IT incidents and provide detailed insights",
        incidents: incidentData
      })
    }
  ],
  temperature: 0.7,
  max_tokens: 4000,
  response_format: { type: "json_object" }
});
```

#### Request Analysis API Call

```typescript
const completion = await openai.chat.completions.create({
  model: "gpt-4-turbo-preview",
  messages: [
    { role: "system", content: systemPrompt },
    {
      role: "user",
      content: JSON.stringify({
        task: "Analyze these IT service requests and provide detailed insights",
        requests: requestData
      })
    }
  ],
  temperature: 0.7,
  max_tokens: 4000,
  response_format: { type: "json_object" }
});
```

## Authentication

The application uses a simple username/password authentication system with hardcoded credentials.

```typescript
const handleSubmit = (e: React.FormEvent) => {
  e.preventDefault();
  
  if (username === 'Onset-ISRA' && password === 'Socorro01@') {
    onLogin();
  } else {
    setError('Invalid credentials');
  }
};
```

For production use, it's recommended to implement a more secure authentication system.

## Backup and Restore

The application includes functionality to backup and restore the application state.

### Backup System

O sistema possui um script de backup automatizado que cria uma cópia completa do projeto. O script está localizado em `scripts/backup.cjs`.

#### Como Executar o Backup

Para criar um backup do projeto, execute o seguinte comando na raiz do projeto:

```bash
node scripts/backup.cjs [nome-do-backup]
```

Exemplo:
```bash
node scripts/backup.cjs backup-v13
```

Se nenhum nome for especificado, o script usará o nome padrão 'backup-v13'.

#### O que é Incluído no Backup

O backup inclui os seguintes diretórios e arquivos:
- Diretório `src` (código fonte)
- Diretório `public` (arquivos públicos)
- Diretório `scripts` (scripts do projeto)
- Arquivos de configuração:
  - package.json
  - package-lock.json
  - vite.config.ts
  - tsconfig.json
  - tsconfig.app.json
  - tsconfig.node.json
  - tailwind.config.js
  - postcss.config.js
  - eslint.config.js
  - index.html
  - Arquivos de documentação (*.md)

#### Localização do Backup

O backup é criado na raiz do projeto com o nome especificado. Por exemplo, se você executar:
```bash
node scripts/backup.cjs backup-v13
```
O backup será criado em:
```
C:\ITSM-Dashboard V2\backup-v13
```

### Restore Functionality

```javascript
async function restoreBackup(backupFile) {
  if (!backupFile) {
    // List available backups
    const backupDir = path.join(__dirname, '..', 'backups');
    if (!fs.existsSync(backupDir)) {
      console.error('Backup directory not found!');
      process.exit(1);
    }

    const backups = fs.readdirSync(backupDir)
      .filter(file => file.startsWith('backup-') && file.endsWith('.zip'))
      .sort()
      .reverse();

    if (backups.length === 0) {
      console.error('No backups found!');
      process.exit(1);
    }

    console.log('Available backups:');
    backups.forEach((backup, index) => {
      const stats = fs.statSync(path.join(backupDir, backup));
      const size = (stats.size / 1024 / 1024).toFixed(2);
      console.log(`${index + 1}. ${backup} (${size} MB)`);
    });
    process.exit(0);
  }

  const backupDir = path.join(__dirname, '..', 'backups');
  const backupPath = path.join(backupDir, backupFile);

  if (!fs.existsSync(backupPath)) {
    console.error(`Backup not found: ${backupFile}`);
    process.exit(1);
  }

  // Create temp directory for extraction
  const tempDir = path.join(__dirname, '..', 'temp');
  if (fs.existsSync(tempDir)) {
    fs.rmSync(tempDir, { recursive: true, force: true });
  }
  fs.mkdirSync(tempDir, { recursive: true });

  try {
    // Extract backup
    const zip = new AdmZip(backupPath);
    zip.extractAllTo(tempDir, true);

    // Files to restore
    const files = [
      'src',
      'public',
      'index.html',
      'package.json',
      'package-lock.json',
      'tsconfig.json',
      'tsconfig.app.json',
      'tsconfig.node.json',
      'vite.config.ts',
      'tailwind.config.js',
      'postcss.config.js',
      'eslint.config.js'
    ];

    // Copy files back to project
    files.forEach(file => {
      const sourcePath = path.join(tempDir, file);
      const targetPath = path.join(__dirname, '..', file);
      
      if (fs.existsSync(sourcePath)) {
        if (fs.existsSync(targetPath)) {
          fs.rmSync(targetPath, { recursive: true, force: true });
        }
        fs.cpSync(sourcePath, targetPath, { recursive: true, force: true });
      }
    });

    // Cleanup temp directory
    fs.rmSync(tempDir, { recursive: true, force: true });

    console.log(`Backup restored successfully: ${backupFile}`);
    console.log('Run npm install to reinstall dependencies');
  } catch (error) {
    console.error('Error restoring backup:', error.message);
    process.exit(1);
  }
}
```

## Deployment

### Building for Production

1. Create environment file:
   
   Create a `.env.production` file:
   ```
   VITE_APP_ENV=production
   VITE_APP_TITLE="IT Operations Dashboard"
   VITE_OPENAI_API_KEY=your_openai_api_key
   ```

2. Build the application:
   ```bash
   npm run build
   ```

3. The build output will be in the `dist` directory, which can be deployed to any static hosting service.

### Deployment Options

#### Static Hosting Services

- **Netlify**: Deploy using Netlify CLI or GitHub integration
- **Vercel**: Deploy using Vercel CLI or GitHub integration
- **GitHub Pages**: Deploy the `dist` directory to GitHub Pages
- **AWS S3**: Upload the `dist` directory to an S3 bucket configured for static website hosting

#### Traditional Web Servers

- **Nginx**: Configure Nginx to serve the `dist` directory
- **Apache**: Configure Apache to serve the `dist` directory

#### Docker Deployment

Create a `Dockerfile`:
```dockerfile
FROM node:18-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

## Performance Considerations

### Data Processing Optimization

- **Sampling for AI Analysis**: For large datasets, the application samples a subset of incidents/requests to send to the OpenAI API
- **Pagination**: Implemented for large data tables
- **Memoization**: Used extensively with `useMemo` and `useCallback` to prevent unnecessary re-renders
- **Lazy Loading**: Components are loaded only when needed

### Rendering Optimization

- **Virtualization**: Consider implementing virtualization for long lists
- **Code Splitting**: Implement code splitting for larger components
- **Image Optimization**: Use optimized images and lazy loading

### Memory Management

- **Data Cleanup**: Clear unused data when switching between views
- **Limit Dataset Size**: Consider implementing limits on the number of records that can be imported

## Security Considerations

### Data Security

- **Client-Side Processing**: All data is processed client-side, minimizing data exposure
- **No Data Persistence**: Data is not persisted between sessions unless manually backed up
- **API Key Protection**: OpenAI API key is stored in environment variables

### Authentication Security

- **Simple Authentication**: Basic username/password authentication
- **No Session Persistence**: Authentication state is not persisted between page reloads

### API Security

- **Rate Limiting**: Consider implementing rate limiting for OpenAI API calls
- **Data Anonymization**: Consider anonymizing sensitive data before sending to OpenAI API

## Future Enhancements

### Potential Improvements

1. **Backend Integration**: Add a backend server for persistent data storage
2. **User Management**: Implement multi-user support with role-based access control
3. **Real-time Updates**: Add WebSocket support for real-time data updates
4. **Advanced Filtering**: Enhance search and filter capabilities
5. **Export Functionality**: Add PDF and Excel export options for reports
6. **Mobile App**: Develop a companion mobile application
7. **Notification System**: Implement alerts for critical incidents
8. **Integration with ITSM Tools**: Direct integration with ServiceNow, Jira, etc.
9. **Custom Dashboards**: Allow users to create personalized dashboard views
10. **Automated Reporting**: Scheduled report generation and distribution

### Technical Debt

1. **Refactor Large Components**: Break down large components into smaller, more manageable pieces
2. **Improve Type Safety**: Enhance TypeScript types and interfaces
3. **Implement Testing**: Add unit and integration tests
4. **Optimize Performance**: Further optimize for large datasets
5. **Enhance Error Handling**: Implement more robust error handling and recovery

## Troubleshooting

### Common Issues

#### Data Import Issues

- **Issue**: Excel file fails to import
- **Solution**: Ensure the file has the correct column headers and data format
- **Solution**: Check for special characters or formatting issues in the Excel file

#### Chart Rendering Issues

- **Issue**: Charts not rendering correctly
- **Solution**: Ensure there is sufficient data for the selected date range
- **Solution**: Check browser console for JavaScript errors

#### Authentication Issues

- **Issue**: Unable to log in
- **Solution**: Verify credentials (Username: `Onset-ISRA`, Password: `Socorro01@`)
- **Solution**: Clear browser cache and cookies

#### Performance Issues

- **Issue**: Dashboard becomes slow with large datasets
- **Solution**: Limit the date range for analysis
- **Solution**: Close unused analysis panels
- **Solution**: Consider using a more powerful device

### Error Messages

#### "Failed to fetch" errors

- **Cause**: OpenAI API key is invalid or has reached its limit
- **Solution**: Check the OpenAI API key in the environment variables
- **Solution**: Verify API key has sufficient quota

#### "No data found" errors

- **Cause**: No data matches the current filter criteria
- **Solution**: Broaden the filter criteria
- **Solution**: Check that the imported data contains the expected fields

## FAQ

### General Questions

**Q: How many incidents/requests can the dashboard handle?**  
A: The dashboard can handle thousands of records, but performance may degrade with very large datasets. For optimal performance, limit to 10,000 records.

**Q: Is my data sent to any external servers?**  
A: Your incident and request data is processed entirely in your browser, except when using the AI analysis features, which send anonymized data to OpenAI's API.

**Q: Can I export analysis results?**  
A: The current version does not support exporting results. This feature may be added in future updates.

**Q: How accurate is the AI analysis?**  
A: The AI analysis provides insights based on patterns in your data. Its accuracy depends on the quality and quantity of your data. The system provides confidence scores for its analysis.

### Technical Questions

**Q: What browsers are supported?**  
A: The dashboard works best in modern browsers like Chrome, Firefox, Edge, and Safari.

**Q: Can I customize the dashboard?**  
A: The current version does not support customization. Future versions may include this feature.

**Q: How is the SLA calculated?**  
A: SLA is calculated based on the time between incident opening and resolution, compared against thresholds defined for each priority level:
- P1: 1 hour
- P2: 4 hours
- P3: 36 hours
- P4: 72 hours

**Q: How do I update the application?**  
A: Create a backup, then replace the application files with the new version. Restore your data if needed.